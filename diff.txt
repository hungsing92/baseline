diff --git a/generate_gt.py b/generate_gt.py
index 6b489ba..81a4162 100755
--- a/generate_gt.py
+++ b/generate_gt.py
@@ -16,7 +16,7 @@ root_dir = "/home/hhs/4T/datasets/KITTI/object/training"
 label_path = os.path.join(root_dir, "label_2/")
 calib_path = os.path.join(root_dir, "calib/")
 gt_path='/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d'
-classes = {'__background__':0, 'Car':1}#, 'Van':1, 'Truck':1, 'Tram':1}
+classes = {'__background__':0, 'Car':1, 'Van':1}#, 'Van':1, 'Truck':1, 'Tram':1}
 
 def load_kitti_calib(calib_path,index):
     """
@@ -121,21 +121,21 @@ for i in range(7481):
 			gt_boxes3d.append(box3d)
 			gt_labels.append(clss)
 		# z_1=z_1+np.sum(box3d[:,2])/8
-		z_1=z_1+h
-		h_.append(h)
-	z=z+z_1/num_objs
+	# 	z_1=z_1+h
+	# 	h_.append(h)
+	# z=z+z_1/num_objs
 	# print(z_1/num_objs)
 	if len(gt_labels) == 0:
 		continue
 	gt_boxes3d = np.array(gt_boxes3d,dtype=np.float32)
 	gt_labels  = np.array(gt_labels ,dtype=np.uint8)
 
-	# np.save('/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d/gt_boxes3d_%05d.npy'%i,gt_boxes3d)
-	# np.save('/home/hhs/4T/datasets/dummy_datas/seg/gt_labels/gt_labels_%05d.npy'%i,gt_labels)
-print(z/7481)
-print(np.mean(h_))
-print(min(h_))
-print(max(h_))
+	np.save('/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d/gt_boxes3d_%05d.npy'%i,gt_boxes3d)
+	np.save('/home/hhs/4T/datasets/dummy_datas/seg/gt_labels/gt_labels_%05d.npy'%i,gt_labels)
+# print(z/7481)
+# print(np.mean(h_))
+# print(min(h_))
+# print(max(h_))
 
 
 
diff --git a/net/__pycache__/common.cpython-35.pyc b/net/__pycache__/common.cpython-35.pyc
index f56622c..4f56b00 100644
Binary files a/net/__pycache__/common.cpython-35.pyc and b/net/__pycache__/common.cpython-35.pyc differ
diff --git a/net/__pycache__/rcnn_nms_op.cpython-35.pyc b/net/__pycache__/rcnn_nms_op.cpython-35.pyc
index 43567f3..daba5f9 100644
Binary files a/net/__pycache__/rcnn_nms_op.cpython-35.pyc and b/net/__pycache__/rcnn_nms_op.cpython-35.pyc differ
diff --git a/net/__pycache__/rpn_nms_op.cpython-35.pyc b/net/__pycache__/rpn_nms_op.cpython-35.pyc
index 7f193d3..7b2edac 100644
Binary files a/net/__pycache__/rpn_nms_op.cpython-35.pyc and b/net/__pycache__/rpn_nms_op.cpython-35.pyc differ
diff --git a/net/__pycache__/rpn_target_op.cpython-35.pyc b/net/__pycache__/rpn_target_op.cpython-35.pyc
index 9b2c2f8..4ffb861 100644
Binary files a/net/__pycache__/rpn_target_op.cpython-35.pyc and b/net/__pycache__/rpn_target_op.cpython-35.pyc differ
diff --git a/net/common.py b/net/common.py
index 25e62a1..91c5360 100755
--- a/net/common.py
+++ b/net/common.py
@@ -5,7 +5,7 @@ SEED = 202
 TOP_Y_MIN=-20  #40
 TOP_Y_MAX=+20
 TOP_X_MIN=0
-TOP_X_MAX=40   #70.4
+TOP_X_MAX=70.4   #70.4
 TOP_Z_MIN=-2.0    ###<todo> determine the correct values!
 TOP_Z_MAX= 0.4
 
diff --git a/net/rpn_nms_op.py b/net/rpn_nms_op.py
index af76b58..cc6392b 100755
--- a/net/rpn_nms_op.py
+++ b/net/rpn_nms_op.py
@@ -175,8 +175,8 @@ def rpn_nms_generator(
         keep = nms(np.hstack((proposals, scores)), nms_thresh)
         if (nms_post_topn > 0) and (len(keep)>nms_post_topn):
             keep = keep[:nms_post_topn]
-            proposals = proposals[keep, :]
-            scores = scores[keep]
+        proposals = proposals[keep, :]
+        scores = scores[keep]
 
         # Output rois blob
         # Our RPN implementation only supports a single input image, so all
diff --git a/outputs/check_points/checkpoint b/outputs/check_points/checkpoint
index 275a950..f390ff0 100644
--- a/outputs/check_points/checkpoint
+++ b/outputs/check_points/checkpoint
@@ -1,6 +1,5 @@
-model_checkpoint_path: "snap_ResNet_vgg_double_up_rm_fc_NGT_040000.ckpt"
-all_model_checkpoint_paths: "snap_ResNet_vgg_double_up_rm_fc_NGT_020000.ckpt"
-all_model_checkpoint_paths: "snap_ResNet_vgg_double_up_rm_fc_NGT_025000.ckpt"
-all_model_checkpoint_paths: "snap_ResNet_vgg_double_up_rm_fc_NGT_030000.ckpt"
-all_model_checkpoint_paths: "snap_ResNet_vgg_double_up_rm_fc_NGT_035000.ckpt"
-all_model_checkpoint_paths: "snap_ResNet_vgg_double_up_rm_fc_NGT_040000.ckpt"
+model_checkpoint_path: "snap_RVD_new_lidar_020000.ckpt"
+all_model_checkpoint_paths: "snap_RVD_new_lidar_005000.ckpt"
+all_model_checkpoint_paths: "snap_RVD_new_lidar_010000.ckpt"
+all_model_checkpoint_paths: "snap_RVD_new_lidar_015000.ckpt"
+all_model_checkpoint_paths: "snap_RVD_new_lidar_020000.ckpt"
diff --git a/read_lidar_new.py b/read_lidar_new.py
index 5c09371..78a5ec1 100755
--- a/read_lidar_new.py
+++ b/read_lidar_new.py
@@ -23,7 +23,7 @@ def lidar_to_top(lidar):
     Z0, Zn = 0, int((TOP_Z_MAX-TOP_Z_MIN)//TOP_Z_DIVISION)+1
     width  = Yn - Y0
     height   = Xn - X0
-    channel = Zn - Z0  + 1
+    channel = Zn - Z0  + 2
 
     pxs=lidar[:,0]
     pys=lidar[:,1]
@@ -45,12 +45,20 @@ def lidar_to_top(lidar):
     qzs=((pzs-TOP_Z_MIN)//TOP_Z_DIVISION).astype(np.int32)
 
     print('height,width,channel=%d,%d,%d'%(height,width,channel))
-    top = np.zeros(shape=(height,width,channel), dtype=np.float32)
+    top = np.ones(shape=(height,width,channel), dtype=np.float32)*TOP_Z_MIN
+    top[:,:,-2:]=0
+    mask = np.ones(shape=(height,width,channel-1), dtype=np.float32)* -5
     # pdb.set_trace()
 
     for i in range(len(pxs)):
-        top[-qxs[i], -qys[i], qzs[i]] = prs[i]
+        # top[-qxs[i], -qys[i], qzs[i]] = qzs[i]*TOP_Z_DIVISION+TOP_Z_MIN
         top[-qxs[i], -qys[i], -1]= 1+ top[-qxs[i], -qys[i], -1]
+        if pzs[i]>mask[-qxs[i], -qys[i],qzs[i]]:
+            top[-qxs[i], -qys[i], qzs[i]] = pzs[i]
+            mask[-qxs[i], -qys[i],qzs[i]]=pzs[i]
+        if pzs[i]>mask[-qxs[i], -qys[i],-1]:
+            mask[-qxs[i], -qys[i],-1]=pzs[i]
+            top[-qxs[i], -qys[i], -2]=prs[i]
 
 
 
@@ -92,7 +100,8 @@ def lidar_to_top(lidar):
 #         pass
 
 #     print("speed:%fs"%(time()-start))
-
+    top[:,:,:-2]=top[:,:,:-2]-TOP_Z_MIN
+    top[top[:,:,:-2]<0]=0
     top[:,:,-1] = np.log(top[:,:,-1]+1)/math.log(64)
 
     if 1:
@@ -145,8 +154,8 @@ for i in range(7481):
     #     fd={lidar_o:lidar}
     #     top,top_image=sess.run([tops,top_images],fd)
     # np.save('/home/hhs/4T/datasets/dummy_datas/seg/lidar/lidar_%05d.npy'%i,lidar)
-    np.save('/home/hhs/4T/datasets/dummy_datas/seg/top_new/top_new%05d.npy'%i,top_new)
-    cv2.imwrite('/home/hhs/4T/datasets/dummy_datas/seg/density_image/density_image_%05d.png'%i,density_image)
+    np.save('/home/hhs/4T/datasets/dummy_datas/seg/top_70/top_70%05d.npy'%i,top_new)
+    cv2.imwrite('/home/hhs/4T/datasets/dummy_datas/seg/density_image_70/density_image_70%05d.png'%i,density_image)
    
    
     
diff --git a/test_ResNet.py b/test_ResNet.py
index ca9c3af..3cbcf84 100644
--- a/test_ResNet.py
+++ b/test_ResNet.py
@@ -63,7 +63,8 @@ def load_dummy_datas():
 
     fig = mlab.figure(figure=None, bgcolor=(0,0,0), fgcolor=None, engine=None, size=(1000, 1000))
     index=np.load('/home/hhs/4T/datasets/dummy_datas/seg/val_list.npy')
-    index=sorted(index)[600:640]
+    index=np.array(sorted(index)[:40], dtype=np.int32)
+    # index= np.arange(2000,2040)
     print('len(index):%d'%len(index))
     # pdb.set_trace()
     if num_frames==[]:
@@ -71,15 +72,16 @@ def load_dummy_datas():
         print('num_frames:%d'%num_frames)
     for n in range(num_frames):
         print(n)
-        rgb   = cv2.imread('/home/hhs/4T/datasets/KITTI/object/training/image_2/0%s.png'%str(index[n]),1).astype(np.float32, copy=False)
+        rgb   = cv2.imread('/home/hhs/4T/datasets/KITTI/object/training/image_2/0%05d.png'%(index[n]),1).astype(np.float32, copy=False)
         rgbs_norm0=(rgb-PIXEL_MEANS)/255
-        lidar = np.load('/home/hhs/4T/datasets/dummy_datas/seg/lidar/lidar_%s.npy'%str(index[n]))
-        top   = np.load('/home/hhs/4T/datasets/dummy_datas/seg/top/top_%s.npy'%str(index[n]))
+        lidar = np.load('/home/hhs/4T/datasets/dummy_datas/seg/lidar/lidar_%05d.npy'%(index[n]))
+        # top   = np.load('/home/hhs/4T/datasets/dummy_datas/seg/top/top_%s.npy'%str(index[n]))
+        top   = np.load('/home/hhs/4T/datasets/dummy_datas/seg/top_70/top_70%05d.npy'%(index[n]))
         front = np.zeros((1,1),dtype=np.float32)
-        gt_label  = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_labels/gt_labels_%s.npy'%str(index[n]))
-        gt_box3d = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d/gt_boxes3d_%s.npy'%str(index[n]))
-
+        gt_label  = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_labels/gt_labels_%05d.npy'%(index[n]))
+        gt_box3d = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d/gt_boxes3d_%05d.npy'%(index[n]))
 
+ 
         # rgb_shape   = rgb.shape
         # gt_rgb   = project_to_rgb_roi  (gt_box3d  )
         # keep = np.where((gt_rgb[:,1]>=-200) & (gt_rgb[:,2]>=-200) & (gt_rgb[:,3]<=(rgb_shape[1]+200)) & (gt_rgb[:,4]<=(rgb_shape[0]+200)))[0]
@@ -87,7 +89,8 @@ def load_dummy_datas():
         # gt_box3d=gt_box3d[keep]
 
 
-        top_image   = cv2.imread('/home/hhs/4T/datasets/dummy_datas/seg/top_image/top_image_%s.png'%str(index[n]),1)
+        # top_image   = cv2.imread('/home/hhs/4T/datasets/dummy_datas/seg/top_image/top_image_%s.png'%str(index[n]),1)
+        top_image   = cv2.imread('/home/hhs/4T/datasets/dummy_datas/seg/density_image_70/density_image_70%05d.png'%(index[n]),1)
         front_image = np.zeros((1,1,3),dtype=np.float32)
 
         rgbs.append(rgb)
@@ -191,6 +194,8 @@ def run_test():
         scales=np.array([1.7,2.4])
         bases=np.array([[-19.5, -8, 19.5, 8],
                         [-8, -19.5, 8, 19.5],
+                        # [-27.5, -11, 27.5, 11],
+                        # [-11, -27.5, 11, 27.5],
                         [-5, -3, 5, 3],
                         [-3, -5, 3, 5]
                         ])
@@ -203,7 +208,7 @@ def run_test():
         top_shape   = tops[0].shape
         front_shape = fronts[0].shape
         rgb_shape   = rgbs[0].shape
-        top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
+        top_feature_shape = ((top_shape[0]-1)//stride, (top_shape[1]-1)//stride+1)
         out_shape=(8,3)
 
 
diff --git a/test_ResNet_vgg_double_up.py b/test_ResNet_vgg_double_up.py
index a602c27..f39d709 100644
--- a/test_ResNet_vgg_double_up.py
+++ b/test_ResNet_vgg_double_up.py
@@ -63,7 +63,8 @@ def load_dummy_datas():
     fig = mlab.figure(figure=None, bgcolor=(0,0,0), fgcolor=None, engine=None, size=(1000, 500))
     files_list=glob.glob(data_root+'seg/rgb/*.png')
     index=np.array([file_index.strip().split('/')[-1][10:10+5] for file_index in files_list ])
-    num_frames=len(files_list)
+    # num_frames=len(files_list)
+    num_frames=30
     index=sorted(index)
     print('len(index):%d'%len(index))
     # pdb.set_trace()
@@ -76,7 +77,7 @@ def load_dummy_datas():
         rgb=np.float32(rgb)
         rgbs_norm0=(rgb-PIXEL_MEANS)/255
         lidar = np.load(data_root+'seg/lidar/lidar_%05d.npy'%n)
-        top   = np.load(data_root+'seg/top/top_%05d.npy'%n)
+        top   = np.load(data_root+'seg/top_new/top_new%05d.npy'%n)
         front = np.zeros((1,1),dtype=np.float32)
         # gt_label  = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_labels/gt_labels_%s.npy'%str(index[n]))
         # gt_box3d = np.load('/home/hhs/4T/datasets/dummy_datas/seg/gt_boxes3d/gt_boxes3d_%s.npy'%str(index[n]))
@@ -89,7 +90,7 @@ def load_dummy_datas():
         # gt_box3d=gt_box3d[keep]
 
 
-        top_image   = cv2.imread(data_root+'seg/top_image/top_image_%05d.png'%n,1)
+        top_image   = cv2.imread(data_root+'seg/density_image/density_image_%05d.png'%n,1)
         # top_image   = np.int32(top_image)
         front_image = np.zeros((1,1,3),dtype=np.float32)
 
@@ -193,10 +194,12 @@ def run_test():
         #     ratios=ratios,
         #     scales=scales
         # )
-        ratios=np.array([1.7,2.4])
+        ratios=np.array([1.7,2.4,3])
         scales=np.array([1.7,2.4])
         bases=np.array([[-19.5, -8, 19.5, 8],
                         [-8, -19.5, 8, 19.5],
+                        [-27.5, -11, 27.5, 11],
+                        [-11, -27.5, 11, 27.5],
                         [-5, -3, 5, 3],
                         [-3, -5, 3, 5]
                         ])
@@ -209,7 +212,7 @@ def run_test():
         top_shape   = tops[0].shape
         front_shape = fronts[0].shape
         rgb_shape   = rgbs[0].shape
-        top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
+        top_feature_shape = ((top_shape[0]-1)//stride, (top_shape[1]-1)//stride+1)
         out_shape=(8,3)
 
 
@@ -270,7 +273,7 @@ def run_test():
         saver  = tf.train.Saver()  
 
 
-        saver.restore(sess, './outputs/check_points/snap_RVD_FreezeBN_NGT_OHEM_s_070000.ckpt')  
+        saver.restore(sess, './outputs/check_points/snap_ResNet_vgg_double_up_rm_fc_NGT_new_lidar_070000.ckpt')  
 
 
         batch_top_cls_loss =0
diff --git a/train_ResNet_vgg_double_up_c.py b/train_ResNet_vgg_double_up_c.py
index ef85132..5ae2ecd 100755
--- a/train_ResNet_vgg_double_up_c.py
+++ b/train_ResNet_vgg_double_up_c.py
@@ -30,28 +30,7 @@ from tensorflow.python import debug as tf_debug
 
 #http://3dimage.ee.tsinghua.edu.cn/cxz
 # "Multi-View 3D Object Detection Network for Autonomous Driving" - Xiaozhi Chen, CVPR 2017
-
-
-def load_dummy_data():
-    rgb   = np.load(data_root+'one_frame/rgb.npy')
-    lidar = np.load(data_root+'one_frame/lidar.npy')
-    top   = np.load(data_root+'one_frame/top.npy')
-    front = np.zeros((1,1),dtype=np.float32)
-    gt_labels    = np.load(data_root+'one_frame/gt_labels.npy')
-    gt_boxes3d   = np.load(data_root+'one_frame/gt_boxes3d.npy')
-    gt_top_boxes = np.load(data_root+'one_frame/gt_top_boxes.npy')
-
-    top_image   = cv2.imread(data_root+'one_frame/top_image.png')
-    front_image = np.zeros((1,1,3),dtype=np.float32)
-
-    rgb =(rgb*255).astype(np.uint8)
-    rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
-    gt_boxes3d = gt_boxes3d.reshape(-1,8,3)
-
-    return  rgb, top, front, gt_labels, gt_boxes3d, top_image, front_image, lidar
-
-
-
+MM_PER_VIEW1 = 180, 70, 30, [1,1,0]
 def load_dummy_datas(index):
 
     num_frames = []
@@ -76,20 +55,20 @@ def load_dummy_datas(index):
         print('processing img:%d,%05d'%(n,int(index[n])))
         rgb   = cv2.imread(kitti_img_root+'/object/training/image_2/%06d.png'%int(index[n]))
         rgbs_norm0=(rgb-PIXEL_MEANS)/255
-        # lidar = np.load(data_root+'seg/lidar/lidar_%05d.npy'%index[n]
-        top   = np.load(data_root+'seg/top/top_%05d.npy'%int(index[n]))
+        # lidar = np.load(data_root+'seg/lidar/lidar_%05d.npy'%int(index[n]))
+        top   = np.load(data_root+'seg/top_70/top_70%05d.npy'%int(index[n]))
         front = np.zeros((1,1),dtype=np.float32)
         gt_label  = np.load(data_root+'seg/gt_labels/gt_labels_%05d.npy'%int(index[n]))
         gt_box3d = np.load(data_root+'seg/gt_boxes3d/gt_boxes3d_%05d.npy'%int(index[n]))
 
         rgb_shape   = rgb.shape
-        gt_rgb   = project_to_rgb_roi  (gt_box3d  )
-        keep = np.where((gt_rgb[:,1]>=-200) & (gt_rgb[:,2]>=-200) & (gt_rgb[:,3]<=(rgb_shape[1]+200)) & (gt_rgb[:,4]<=(rgb_shape[0]+200)))[0]
-        gt_label=gt_label[keep]
-        gt_box3d=gt_box3d[keep]
+        # gt_rgb   = project_to_rgb_roi  (gt_box3d  )
+        # keep = np.where((gt_rgb[:,1]>=-200) & (gt_rgb[:,2]>=-200) & (gt_rgb[:,3]<=(rgb_shape[1]+200)) & (gt_rgb[:,4]<=(rgb_shape[0]+200)))[0]
+        # gt_label=gt_label[keep]
+        # gt_box3d=gt_box3d[keep]
 
 
-        top_image   = cv2.imread(data_root+'seg/top_image/top_image_%05d.png'%int(index[n]))
+        top_image   = cv2.imread(data_root+'seg/density_image_70/density_image_70%05d.png'%int(index[n]))
         front_image = np.zeros((1,1,3),dtype=np.float32)
 
         rgbs.append(rgb)
@@ -113,13 +92,14 @@ def load_dummy_datas(index):
 
             imshow('rgb',rgb1)
             imshow('top_image',top_image1)
-
+            azimuth,elevation,distance,focalpoint = MM_PER_VIEW1
+            mlab.view(azimuth,elevation,distance,focalpoint)
             mlab.clf(fig)
             draw_lidar(lidar, fig=fig)
             draw_gt_boxes3d(gt_box3d, fig=fig)
             mlab.show(1)
             cv2.waitKey(0)
-
+            mlab.close()
             pass
     # pdb.set_trace()
     # rgbs=np.array(rgbs)
@@ -187,10 +167,12 @@ def run_train():
         #     ratios=ratios,
         #     scales=scales
         # )
-        ratios=np.array([1.7,2.4])
+        ratios=np.array([1.7,2.4,2.7])
         scales=np.array([1.7,2.4])
         bases=np.array([[-19.5, -8, 19.5, 8],
                         [-8, -19.5, 8, 19.5],
+                        # [-27.5, -11, 27.5, 11],
+                        # [-11, -27.5, 11, 27.5],
                         [-5, -3, 5, 3],
                         [-3, -5, 3, 5]
                         ])
@@ -206,6 +188,7 @@ def run_train():
         top_shape   = tops[0].shape
         front_shape = fronts[0].shape
         rgb_shape   = rgbs[0].shape
+        # top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
         top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
         # pdb.set_trace()
         # set anchor boxes
@@ -272,7 +255,7 @@ def run_train():
     l2 = l2_regulariser(decay=0.00001)
     tf.summary.scalar('l2', l2)
     learning_rate = tf.placeholder(tf.float32, shape=[])
-    rate=0.0001
+    rate=0.0005
     solver = tf.train.AdamOptimizer(learning_rate)
     # solver = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)
     #solver_step = solver.minimize(top_cls_loss+top_reg_loss+l2)
@@ -287,19 +270,19 @@ def run_train():
 
     num_ratios=len(ratios)
     num_scales=len(scales)
-    fig, axs = plt.subplots(num_ratios,num_scales)
+    # fig, axs = plt.subplots(num_ratios,num_scales)
 
     merged = tf.summary.merge_all()
 
     sess = tf.InteractiveSession()  
-    train_writer = tf.summary.FileWriter( './outputs/tensorboard/Res_Vgg_double_up_rm_fc',
+    train_writer = tf.summary.FileWriter( './outputs/tensorboard/RVD_ohem',
                                       sess.graph)
     with sess.as_default():
         sess.run( tf.global_variables_initializer(), { IS_TRAIN_PHASE : True } )
         # sess = tf_debug.LocalCLIDebugWrapperSession(sess)
         # summary_writer = tf.summary.FileWriter(out_dir+'/tf', sess.graph)
         saver  = tf.train.Saver() 
-        saver.restore(sess, './outputs/check_points/snap_ResNet_vgg_double_up_rm_fc_NGT_070000.ckpt') 
+        saver.restore(sess, './outputs/check_points/snap_RVD_FreezeBN_NGT_OHEM_s_070000.ckpt') 
         # # saver.restore(sess, './outputs/check_points/MobileNet.ckpt')  
 
         # var_lt_res=[v for v in tf.trainable_variables() if v.name.startswith('res')]#resnet_v1_50
@@ -337,7 +320,7 @@ def run_train():
         frame_range = np.arange(num_frames)
         idx=0
         frame=0
-        rate=0.00001
+        rate=0.00005
         for iter in range(max_iter):
             epoch=iter//num_frames+1
             # rate=0.001
@@ -374,7 +357,7 @@ def run_train():
                 idx=0
             print('processing image : %s'%image_index[idx])
 
-            if (iter+1)%(10000)==0:
+            if (iter+1)%(20000)==0:
                 rate=0.8*rate
 
             rgb_shape   = rgbs[idx].shape
@@ -421,22 +404,22 @@ def run_train():
 
             batch_rois3d	 = project_to_roi3d    (batch_top_rois)
             batch_front_rois = project_to_front_roi(batch_rois3d  )
-            batch_rgb_rois   = project_to_rgb_roi  (batch_rois3d, , rgb_shape[1], rgb_shape[0])
+            batch_rgb_rois   = project_to_rgb_roi  (batch_rois3d, rgb_shape[1], rgb_shape[0])
 
 
-            keep = np.where((batch_rgb_rois[:,1]>=-100) & (batch_rgb_rois[:,2]>=-100) & (batch_rgb_rois[:,3]<=(rgb_shape[1]+100)) & (batch_rgb_rois[:,4]<=(rgb_shape[0]+100)))[0]
-            batch_rois3d        = batch_rois3d[keep]      
-            batch_front_rois    = batch_front_rois[keep]
-            batch_rgb_rois      = batch_rgb_rois[keep]  
-            batch_proposal_scores=batch_proposal_scores[keep]
-            batch_top_rois      =batch_top_rois[keep]
-            batch_fuse_labels   =batch_fuse_labels[keep]
-            batch_fuse_targets  =batch_fuse_targets[keep]
+            # keep = np.where((batch_rgb_rois[:,1]>=-100) & (batch_rgb_rois[:,2]>=-100) & (batch_rgb_rois[:,3]<=(rgb_shape[1]+100)) & (batch_rgb_rois[:,4]<=(rgb_shape[0]+100)))[0]
+            # batch_rois3d        = batch_rois3d[keep]      
+            # batch_front_rois    = batch_front_rois[keep]
+            # batch_rgb_rois      = batch_rgb_rois[keep]  
+            # batch_proposal_scores=batch_proposal_scores[keep]
+            # batch_top_rois      =batch_top_rois[keep]
+            # batch_fuse_labels   =batch_fuse_labels[keep]
+            # batch_fuse_targets  =batch_fuse_targets[keep]
 
-            if len(batch_rois3d)==0:
-                # pdb.set_trace()
-                idx=idx+1
-                continue
+            # if len(batch_rois3d)==0:
+            #     # pdb.set_trace()
+            #     idx=idx+1
+            #     continue
 
 
 
@@ -509,7 +492,7 @@ def run_train():
 
                 batch_fuse_probs, batch_fuse_deltas = \
                     sess.run([ fuse_probs, fuse_deltas ],fd2)
-
+                # pdb.set_trace()
                 #batch_fuse_deltas=0*batch_fuse_deltas #disable 3d box prediction
                 probs, boxes3d = rcnn_nms(batch_fuse_probs, batch_fuse_deltas, batch_rois3d, threshold=0.05)
 
@@ -546,7 +529,7 @@ def run_train():
             # save: ------------------------------------
             if (iter)%5000==0 and (iter!=0):
                 #saver.save(sess, out_dir + '/check_points/%06d.ckpt'%iter)  #iter
-                saver.save(sess, out_dir + '/check_points/snap_ResNet_vgg_double_up_rm_fc_NGT_%06d.ckpt'%iter)  #iter
+                saver.save(sess, out_dir + '/check_points/snap_RVD_new_lidar_%06d.ckpt'%iter)  #iter
                 # saver.save(sess, out_dir + '/check_points/MobileNet.ckpt')  #iter
                 # pdb.set_trace()
                 pass
diff --git a/train_ResNet_vgg_double_up_s.py b/train_ResNet_vgg_double_up_s.py
index 70ad154..eb10fe2 100755
--- a/train_ResNet_vgg_double_up_s.py
+++ b/train_ResNet_vgg_double_up_s.py
@@ -32,27 +32,6 @@ from net.configuration import *
 #http://3dimage.ee.tsinghua.edu.cn/cxz
 # "Multi-View 3D Object Detection Network for Autonomous Driving" - Xiaozhi Chen, CVPR 2017
 
-
-def load_dummy_data():
-    rgb   = np.load(data_root+'one_frame/rgb.npy')
-    lidar = np.load(data_root+'one_frame/lidar.npy')
-    top   = np.load(data_root+'one_frame/top.npy')
-    front = np.zeros((1,1),dtype=np.float32)
-    gt_labels    = np.load(data_root+'one_frame/gt_labels.npy')
-    gt_boxes3d   = np.load(data_root+'one_frame/gt_boxes3d.npy')
-    gt_top_boxes = np.load(data_root+'one_frame/gt_top_boxes.npy')
-
-    top_image   = cv2.imread(data_root+'one_frame/top_image.png')
-    front_image = np.zeros((1,1,3),dtype=np.float32)
-
-    rgb =(rgb*255).astype(np.uint8)
-    rgb = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
-    gt_boxes3d = gt_boxes3d.reshape(-1,8,3)
-
-    return  rgb, top, front, gt_labels, gt_boxes3d, top_image, front_image, lidar
-
-
-
 def load_dummy_datas(index):
 
     num_frames = []
@@ -78,19 +57,19 @@ def load_dummy_datas(index):
         rgb   = cv2.imread(kitti_img_root+'/training/image_2/%06d.png'%int(index[n]))
         rgbs_norm0=(rgb-PIXEL_MEANS)/255
         # lidar = np.load(data_root+'seg/lidar/lidar_%05d.npy'%index[n]
-        top   = np.load(data_root+'seg/top/top_%05d.npy'%int(index[n]))
+        top   = np.load(data_root+'seg/top_70/top_70%05d.npy'%int(index[n]))
         front = np.zeros((1,1),dtype=np.float32)
         gt_label  = np.load(data_root+'seg/gt_labels/gt_labels_%05d.npy'%int(index[n]))
         gt_box3d = np.load(data_root+'seg/gt_boxes3d/gt_boxes3d_%05d.npy'%int(index[n]))
 
         rgb_shape   = rgb.shape
-        gt_rgb   = project_to_rgb_roi  (gt_box3d, rgb_shape[1], rgb_shape[0])
-        keep = np.where((gt_rgb[:,1]>=-200) & (gt_rgb[:,2]>=-200) & (gt_rgb[:,3]<=(rgb_shape[1]+200)) & (gt_rgb[:,4]<=(rgb_shape[0]+200)))[0]
-        gt_label=gt_label[keep]
-        gt_box3d=gt_box3d[keep]
+        # gt_rgb   = project_to_rgb_roi  (gt_box3d, rgb_shape[1], rgb_shape[0])
+        # keep = np.where((gt_rgb[:,1]>=-200) & (gt_rgb[:,2]>=-200) & (gt_rgb[:,3]<=(rgb_shape[1]+200)) & (gt_rgb[:,4]<=(rgb_shape[0]+200)))[0]
+        # gt_label=gt_label[keep]
+        # gt_box3d=gt_box3d[keep]
 
 
-        top_image   = cv2.imread(data_root+'seg/top_image/top_image_%05d.png'%int(index[n]))
+        top_image   = cv2.imread(data_root+'seg/density_image_70/density_image_70%05d.png'%int(index[n]))
         front_image = np.zeros((1,1,3),dtype=np.float32)
 
         rgbs.append(rgb)
@@ -166,6 +145,7 @@ def  project_to_front_roi(rois3d):
 data_root='/home/users/hhs/4T/datasets/dummy_datas/'
 kitti_img_root='/mnt/disk_4T/KITTI/'
 vis=0
+ohem=False
 def run_train():
 
     # output dir, etc
@@ -188,10 +168,12 @@ def run_train():
         #     ratios=ratios,
         #     scales=scales
         # )
-        ratios=np.array([1.7,2.4])
+        ratios=np.array([1.7,2.4,2.7])
         scales=np.array([1.7,2.4])
         bases=np.array([[-19.5, -8, 19.5, 8],
                         [-8, -19.5, 8, 19.5],
+                        [-27.5, -11, 27.5, 11],
+                        [-11, -27.5, 11, 27.5],
                         [-5, -3, 5, 3],
                         [-3, -5, 3, 5]
                         ])
@@ -207,7 +189,8 @@ def run_train():
         top_shape   = tops[0].shape
         front_shape = fronts[0].shape
         rgb_shape   = rgbs[0].shape
-        top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
+        # top_feature_shape = ((top_shape[0]-1)//stride+1, (top_shape[1]-1)//stride+1)
+        top_feature_shape = ((top_shape[0]-1)//stride, (top_shape[1]-1)//stride+1)
         # pdb.set_trace()
         # set anchor boxes
         num_class = 2 #incude background
@@ -306,7 +289,7 @@ def run_train():
         # sess = tf_debug.LocalCLIDebugWrapperSession(sess)
         # summary_writer = tf.summary.FileWriter(out_dir+'/tf', sess.graph)
         saver  = tf.train.Saver() 
-        saver.restore(sess, './outputs/check_points/snap_RVD_FreezeBN_NGT_s_120000.ckpt') 
+        saver.restore(sess, './outputs/check_points/snap_RVD_new_lidar_6s_010000.ckpt') 
         # # saver.restore(sess, './outputs/check_points/MobileNet.ckpt')  
 
         # var_lt_res=[v for v in tf.trainable_variables() if v.name.startswith('res')]#resnet_v1_50
@@ -380,7 +363,7 @@ def run_train():
                 idx=0
             print('processing image : %s'%image_index[idx])
 
-            if (iter+1)%(10000)==0:
+            if (iter+1)%(20000)==0:
                 rate=0.8*rate
 
             rgb_shape   = rgbs[idx].shape
@@ -416,102 +399,70 @@ def run_train():
                 IS_TRAIN_PHASE:  True
             }
             batch_proposals, batch_proposal_scores, batch_top_features = sess.run([proposals, proposal_scores, top_features],fd1)
+            print('Nums of batch_proposals: %d'%len(batch_proposals))
             print(batch_proposal_scores[:50])
-            # pdb.set_trace()
+            
             ## generate  train rois  ------------
             batch_top_inds, batch_top_pos_inds, batch_top_labels, batch_top_targets  = \
                 rpn_target ( anchors, inside_inds_filtered, batch_gt_labels,  batch_gt_top_boxes)
-
-            batch_top_rois, batch_fuse_labels, batch_fuse_targets  = \
-                 rcnn_target_ohem(  batch_proposals, batch_gt_labels, batch_gt_top_boxes, batch_gt_boxes3d )
-
-            # batch_top_rois, batch_fuse_labels, batch_fuse_targets  = \
-            #      rcnn_target(  batch_proposals, batch_gt_labels, batch_gt_top_boxes, batch_gt_boxes3d )
-
-            batch_rois3d	 = project_to_roi3d    (batch_top_rois)
-            batch_front_rois = project_to_front_roi(batch_rois3d  ) 
-            batch_rgb_rois   = project_to_rgb_roi  (batch_rois3d, rgb_shape[1], rgb_shape[0])
-
-            # keep = np.where((batch_rgb_rois[:,1]>=-100) & (batch_rgb_rois[:,2]>=-100) & (batch_rgb_rois[:,3]<=(rgb_shape[1]+100)) & (batch_rgb_rois[:,4]<=(rgb_shape[0]+100)))[0]
-            # batch_rois3d        = batch_rois3d[keep]      
-            # batch_front_rois    = batch_front_rois[keep]
-            # batch_rgb_rois      = batch_rgb_rois[keep]  
-            # batch_proposal_scores=batch_proposal_scores[keep]
-            # batch_top_rois      =batch_top_rois[keep]
-            # batch_fuse_labels   =batch_fuse_labels[keep]
-            # batch_fuse_targets  =batch_fuse_targets[keep]
-            # if len(batch_rois3d)==0:
-            #     # pdb.set_trace()
-            #     idx=idx+1
-            #     continue
-
-
-
-
-            # ##debug gt generation
-            # if vis and iter%iter_debug==0:
-            #     top_image = top_imgs[idx]
-            #     rgb       = rgbs[idx]
-
-            #     img_gt     = draw_rpn_gt(top_image, batch_gt_top_boxes, batch_gt_labels)
-            #     img_label  = draw_rpn_labels (img_gt, anchors, batch_top_inds, batch_top_labels )
-            #     img_target = draw_rpn_targets(top_image, anchors, batch_top_pos_inds, batch_top_targets)
-            #     #imshow('img_rpn_gt',img_gt)
-            #     imshow('img_anchor_label',img_label)
-            #     #imshow('img_rpn_target',img_target)
-
-            #     img_label  = draw_rcnn_labels (top_image, batch_top_rois, batch_fuse_labels )
-            #     img_target = draw_rcnn_targets(top_image, batch_top_rois, batch_fuse_labels, batch_fuse_targets)
-            #     #imshow('img_rcnn_label',img_label)
-            #     if vis :
-            #         imshow('img_rcnn_target',img_target)
-
-
-            #     img_rgb_rois = draw_boxes(rgb, batch_rgb_rois[:,1:5], color=(255,0,255), thickness=1)
-            #     if vis :
-            #         imshow('img_rgb_rois',img_rgb_rois)
-            #         cv2.waitKey(1)
-
-            ## run classification and regression loss -----------
-            fd2={
-				**fd1,
-
-                top_images: batch_top_images,
-                front_images: batch_front_images,
-                rgb_images: batch_rgb_images,
-
-				top_rois:   batch_top_rois,
-                front_rois: batch_front_rois,
-                rgb_rois:   batch_rgb_rois,
-
-                top_inds:     batch_top_inds,
-                top_pos_inds: batch_top_pos_inds,
-                top_labels:   batch_top_labels,
-                top_targets:  batch_top_targets,
-
-                fuse_labels:  batch_fuse_labels,
-                fuse_targets: batch_fuse_targets,
-            }
-            #_, batch_top_cls_loss, batch_top_reg_loss = sess.run([solver_step, top_cls_loss, top_reg_loss],fd2)
-
-            rois_per_image    = CFG.TRAIN.RCNN_BATCH_SIZE
-            fg_rois_per_image = int(np.round(CFG.TRAIN.RCNN_FG_FRACTION * rois_per_image))
-            loss_ohem_, rcnn_smooth_l1_ohem_= sess.run([softmax_loss_ohem, rcnn_smooth_l1_ohem],fd2)
-            loss_ohem_[:len(rcnn_smooth_l1_ohem_)] += rcnn_smooth_l1_ohem_
-            # fg_inds=np.arange(len(rcnn_smooth_l1_ohem_))
-            # if len(rcnn_smooth_l1_ohem_)>fg_rois_per_image:
-            #     fg_inds = np.random.choice(fg_inds, size=fg_rois_per_image, replace=False)
-            #     loss_ohem_[fg_inds]=0
-
-            ohem_ind = np.argsort(-loss_ohem_)[:rois_per_image]
-            batch_top_rois=batch_top_rois[ohem_ind]
-            batch_fuse_labels=batch_fuse_labels[ohem_ind]
-            batch_fuse_targets=batch_fuse_targets[ohem_ind]
             # pdb.set_trace()
+            if ohem==True:
+                batch_top_rois, batch_fuse_labels, batch_fuse_targets  = \
+                     rcnn_target_ohem(  batch_proposals, batch_gt_labels, batch_gt_top_boxes, batch_gt_boxes3d )
+    
+                # batch_top_rois, batch_fuse_labels, batch_fuse_targets  = \
+                #      rcnn_target(  batch_proposals, batch_gt_labels, batch_gt_top_boxes, batch_gt_boxes3d )
+    
+                batch_rois3d	 = project_to_roi3d    (batch_top_rois)
+                batch_front_rois = project_to_front_roi(batch_rois3d  ) 
+                batch_rgb_rois   = project_to_rgb_roi  (batch_rois3d, rgb_shape[1], rgb_shape[0])
+    
+    
+                ## run classification and regression loss -----------
+                fd2={
+			 	**fd1,
+    
+                    top_images: batch_top_images,
+                    front_images: batch_front_images,
+                    rgb_images: batch_rgb_images,
+    
+			 	top_rois:   batch_top_rois,
+                    front_rois: batch_front_rois,
+                    rgb_rois:   batch_rgb_rois,
+    
+                    top_inds:     batch_top_inds,
+                    top_pos_inds: batch_top_pos_inds,
+                    top_labels:   batch_top_labels,
+                    top_targets:  batch_top_targets,
+    
+                    fuse_labels:  batch_fuse_labels,
+                    fuse_targets: batch_fuse_targets,
+                }
+                #_, batch_top_cls_loss, batch_top_reg_loss = sess.run([solver_step, top_cls_loss, top_reg_loss],fd2)
+    
+                rois_per_image    = CFG.TRAIN.RCNN_BATCH_SIZE
+                fg_rois_per_image = int(np.round(CFG.TRAIN.RCNN_FG_FRACTION * rois_per_image))
+                loss_ohem_, rcnn_smooth_l1_ohem_= sess.run([softmax_loss_ohem, rcnn_smooth_l1_ohem],fd2)
+                loss_ohem_[:len(rcnn_smooth_l1_ohem_)] += rcnn_smooth_l1_ohem_
+                # fg_inds=np.arange(len(rcnn_smooth_l1_ohem_))
+                # if len(rcnn_smooth_l1_ohem_)>fg_rois_per_image:
+                #     fg_inds = np.random.choice(fg_inds, size=fg_rois_per_image, replace=False)
+                #     loss_ohem_[fg_inds]=0 
+                # pdb.set_trace()
+                ohem_ind = np.argsort(-loss_ohem_[len(rcnn_smooth_l1_ohem_):])[:(rois_per_image-len(rcnn_smooth_l1_ohem_))]
+                ohem_ind = np.hstack([np.arange(len(rcnn_smooth_l1_ohem_)), ohem_ind])
+                batch_top_rois=batch_top_rois[ohem_ind]
+                batch_fuse_labels=batch_fuse_labels[ohem_ind]
+                batch_fuse_targets=batch_fuse_targets[ohem_ind]
+            else:
+                batch_top_rois, batch_fuse_labels, batch_fuse_targets  = \
+                 rcnn_target(  batch_proposals, batch_gt_labels, batch_gt_top_boxes, batch_gt_boxes3d )
+                # pdb.set_trace()
             batch_rois3d     = project_to_roi3d    (batch_top_rois)
             batch_front_rois = project_to_front_roi(batch_rois3d  ) 
             batch_rgb_rois   = project_to_rgb_roi  (batch_rois3d, rgb_shape[1], rgb_shape[0])
 
+
             fd2={
                 **fd1,
 
@@ -539,7 +490,7 @@ def run_train():
             log.write('%5.1f   %5d    %0.4fs   %0.4f   |   %0.5f   %0.5f   |   %0.5f   %0.5f  \n' %\
 				(epoch, iter, speed, rate, batch_top_cls_loss, batch_top_reg_loss, batch_fuse_cls_loss, batch_fuse_reg_loss))
 
-            print (rcnn_probs[:10,1])
+            # print (rcnn_probs[:10,1])
 
             #print('ok')
             # debug: ------------------------------------
@@ -590,7 +541,7 @@ def run_train():
             # save: ------------------------------------
             if (iter)%5000==0 and (iter!=0):
                 #saver.save(sess, out_dir + '/check_points/%06d.ckpt'%iter)  #iter
-                saver.save(sess, out_dir + '/check_points/snap_RVD_FreezeBN_NGT_OHEM_s_%06d.ckpt'%iter)  #iter
+                saver.save(sess, out_dir + '/check_points/snap_RVD_new_lidar_6s_%06d.ckpt'%iter)  #iter
                 # saver.save(sess, out_dir + '/check_points/MobileNet.ckpt')  #iter
                 # pdb.set_trace()
                 pass
